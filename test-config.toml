# NetabaseStore Test Configuration

# Test Environment Configuration
[test.environment]
# Number of parallel test threads (0 = auto-detect)
threads = 0
# Test timeout in seconds
timeout = 300
# Enable verbose test output
verbose = true
# Test data directory
data_dir = "target/test-data"
# Temporary database directory
temp_db_dir = "target/test-dbs"

# Unit Test Configuration
[test.unit]
# Enable property-based testing
property_testing = true
# Number of property test cases
property_test_cases = 1000
# Enable mutation testing
mutation_testing = false
# Test specific modules only
filter_modules = []

# Component Test Configuration  
[test.component]
# Test with real file system
real_filesystem = true
# Test with different storage backends
test_backends = ["memory", "sled", "redb"]
# Enable performance assertions
performance_assertions = true
# Enable crash simulation tests
crash_simulation = true
# Database size limits for tests (in MB)
max_db_size = 100

# Integration Test Configuration
[test.integration]
# Enable cross-process testing
cross_process = false
# Enable network testing
network_testing = false
# Test with multiple versions
version_compatibility = false
# Enable chaos testing
chaos_testing = false

# API Test Configuration
[test.api]
# Enable load testing
load_testing = true
# Number of concurrent API clients
concurrent_clients = 10
# API test duration (seconds)
test_duration = 60
# Enable API fuzzing
fuzzing = false
# Mock external dependencies
mock_external = true

# Benchmark Configuration
[benchmark]
# Benchmark output format
output_format = "html"
# Benchmark duration (seconds)
duration = 10
# Number of benchmark iterations
iterations = 100
# Enable statistical analysis
statistics = true
# Save benchmark history
save_history = true
# Benchmark data sizes
data_sizes = [1, 10, 100, 1000, 10000]

# Coverage Configuration
[coverage]
# Minimum coverage threshold (percentage)
threshold = 80
# Coverage output format
format = ["html", "lcov"]
# Exclude patterns
exclude = [
    "*/tests/*",
    "*/benches/*", 
    "*/examples/*",
    "**/test_*.rs"
]
# Include only specific modules
include_only = []

# Security Configuration
[security]
# Enable dependency audit
dependency_audit = true
# Enable SAST scanning
static_analysis = false
# Enable fuzzing
fuzzing = false
# Security scan timeout (seconds)
scan_timeout = 600

# Quality Configuration
[quality]
# Enable formatting checks
format_check = true
# Enable clippy linting
clippy = true
# Clippy warning level
clippy_level = "deny"
# Enable documentation checks
doc_check = true
# Enable unused dependency checks
unused_deps = true
# Enable license compatibility checks
license_check = false

# Reporting Configuration
[reporting]
# Output directory for reports
output_dir = "target/test-reports"
# Report formats to generate
formats = ["markdown", "json", "junit"]
# Include detailed error information
detailed_errors = true
# Include performance metrics
performance_metrics = true
# Include coverage in reports
include_coverage = true
# Generate trend analysis
trend_analysis = false

# CI/CD Configuration
[ci]
# Fail fast on first test failure
fail_fast = false
# Retry failed tests
retry_count = 2
# Enable parallel test execution
parallel = true
# Cache test artifacts
cache_artifacts = true
# Generate CI-friendly output
ci_output = true

# Development Configuration
[development]
# Enable watch mode for tests
watch_mode = false
# Auto-fix formatting issues
auto_fix_format = true
# Auto-run tests on file changes
auto_test = false
# Enable debug logging
debug_logging = false

# Feature Flags for Testing
[features]
# Test experimental features
experimental = false
# Test deprecated features
deprecated = true
# Test async functionality
async_support = true
# Test networking features
network_features = false
# Test encryption features
encryption = false